{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disaster News Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNt9Ld7cZuEVJD8wJwEA9Ap"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tdKEBPcz2Lk"
      },
      "source": [
        "# Disaster Related News Classification\r\n",
        "Using Machine Learning toold to categorize Twitter news into disaster related and not disaster related. Using labelled dataset to train the model. Using Naive Bayes model for classification.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dadpuypozxv-"
      },
      "source": [
        "import nltk\r\n",
        "import pandas as pd\r\n",
        "import string\r\n",
        "import random\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "data = pd.read_csv('/disaster_response_messages_training.csv').head(17000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4fwRKVv2rmF"
      },
      "source": [
        "# Checking for inappropriate values\r\n",
        "index = data[data['related'].isin([1, 0]) == False].index\r\n",
        "data.drop(index=index, inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAgB8SCD2EPh"
      },
      "source": [
        "# Taking only the columns we are looking at\r\n",
        "messages = data.message.values\r\n",
        "related = data.related.values\r\n",
        "\r\n",
        "mid = int(len(messages) * 0.8)\r\n",
        "messages_train = messages[:mid]\r\n",
        "related_train = related[:mid]\r\n",
        "messages_test = messages[mid:]\r\n",
        "related_test = related[mid:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTkdyRQrKIcE"
      },
      "source": [
        "def get_feature(message):\r\n",
        "  message = message.lower()\r\n",
        "  tokens = nltk.pos_tag(nltk.word_tokenize(message))\r\n",
        "  tokens = [token[0] for token in tokens if (token[1] not in ['VBZ', 'DT', 'TO', 'EX', 'PDT', 'PRP', 'CD', 'PRP$'])]\r\n",
        "  return tokens"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq_Qz77HJ6Df"
      },
      "source": [
        "# preparing dictionary\r\n",
        "dictionary = []\r\n",
        "for message in messages_train:\r\n",
        "  dictionary.extend(get_feature(message))\r\n",
        "random.shuffle(dictionary)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePcrtmM4YN4x"
      },
      "source": [
        "def grouping(message):\r\n",
        "  return {word: (word in message) for word in dictionary}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AbuU0TjFAr0"
      },
      "source": [
        "# Extracting features\r\n",
        "feature_set = []\r\n",
        "for num, message in enumerate(messages_train):\r\n",
        "  feature = grouping(nltk.word_tokenize(message.lower()))\r\n",
        "  feature_set.append((feature, related_train[num]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU9sAt_JWrYM"
      },
      "source": [
        "# Creating model\r\n",
        "clf = nltk.NaiveBayesClassifier.train(feature_set)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkc6HbXeCobT",
        "outputId": "4e7902a4-4111-4a97-def0-3613fcdafddd"
      },
      "source": [
        "# Prediction for the test bundle we have in our hand and finding the accuracy of the model for that\r\n",
        "prediction = [clf.classify(grouping(nltk.word_tokenize(feature.lower()))) for feature in messages_test]\r\n",
        "accuracy = metrics.accuracy_score(related_test, prediction)\r\n",
        "print(accuracy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8048708048708049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRnHUVlhzUVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba009bd7-59f7-42ea-f1c4-7876a5475d65"
      },
      "source": [
        "# Checking the messages which where predicted wrong\r\n",
        "for num, message in enumerate(messages_test[:30]):\r\n",
        "  prediction = clf.classify(grouping(nltk.word_tokenize(message.lower())))\r\n",
        "  if prediction != related_test[num]:\r\n",
        "    print(message)\r\n",
        "    print(prediction)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The consultant will also arrange for and coordinate the fielding of regular monitoring and field assessment missions, as well as a final evaluation mission.\n",
            "1\n",
            "The earthquake in Pakistan will be the theme of an all-star fundraising gala, with pledges going to German Agro Action.\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKLCF0Rj_0hk"
      },
      "source": [
        "def classify_percentage(message):\r\n",
        "  message = message.lower()\r\n",
        "  sentence_feature = grouping(nltk.word_tokenize(message))\r\n",
        "  probability = clf.prob_classify(sentence_feature)\r\n",
        "  print('related:', probability.prob(1))\r\n",
        "  print('unrelated:', probability.prob(0))\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjdW9KDgXK9C",
        "outputId": "d3028134-f00d-404d-8ee9-85aab4f67366"
      },
      "source": [
        "# Using the model to classify a sentence in percentage\r\n",
        "classify_percentage('Earthquake in Japan')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "related: 0.9518177823159734\n",
            "unrelated: 0.048182217684024545\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}